---
title: "Sample Source Prediction"
author: "Shannon E. Ellis"
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{recount quick start guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r vignetteSetup, echo=FALSE, message=FALSE, warning = FALSE}
## Track time spent on making the vignette
startTime <- Sys.time()
```
# Load libraries

```{r load-packages, message = FALSE, warning = FALSE}
## load libraries
library(devtools)
install_github("leekgroup/phenopredict")
library('phenopredict')
library(rtracklayer)
library(recount)
library(genefilter)
library(plyr)
library(GenomicRanges)
library('R.utils')
library('BiocParallel')

## Set colors
## import colors to use
  bright= c(red=rgb(222,45,38, maxColorValue=255), #de2d26
            pink=rgb( 255, 102, 153, maxColorValue=255), #ff6699
            orange=rgb(232,121,12, maxColorValue=255),   #e8790c
            yellow=rgb(255,222,13, maxColorValue=255), #ffde0d          
            green=rgb(12,189,24, maxColorValue=255),  #0cbd18           
            teal=rgb(59,196,199, maxColorValue=255), #3bc4c7
            blue=rgb(58,158,234, maxColorValue=255), #3a9eea
            purple=rgb(148,12,232, maxColorValue=255)) #940ce8  
```

# Select regions from SRA training data

```{r 'select-regions', message = FALSE, warning = FALSE}
	  #### SRA data [generated in merge_bwtool_by_chunk.R]
	  ## which chunk regions are in [chunk_grp]
	  load('/dcl01/leek/data/sellis/barcoding/data/chunk_grp.Rdata')
	  ## region information [regions]
	  load('/dcl01/leek/data/sellis/barcoding/data/regions-cut0.5.Rdata')
	  reg = regions
	  rm(regions)
	  ## add chunk information to all 1,187,643 regions
	  reg$chunkname <- chunk_grp

	  ## remove noncanoncial chromosomes
	  chunk_name = table(chunk_grp) %>% names()
	  chunk_name = grep("chrUn", chunk_name,invert=T,val=T)
	  chunk_name = grep("random", chunk_name,invert=T,val=T)
	  chunk_name = grep("EBV", chunk_name,invert=T,val=T)
	  chunk_name = grep("chrM", chunk_name,invert=T,val=T)

	  # selecting training and test set samples
	 load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/coverageMatrix-cut0.5-', chunk_name[107], '.Rdata'))
	  set.seed(1567)
	  samples_to_use<-sample(colnames(coverageMatrix), ncol(coverageMatrix)/2 )
	  keep = colnames(coverageMatrix) %in% samples_to_use

	## load SRA metadata
	### Load in SRA metadata
	phenot="SampleSource"

	load('/dcl01/leek/data/recount-website/metadata/metadata_sra.Rdata')
	metadata <- metadata[!is.na(metadata$bigwig_path), ]
	sra_meta = metadata
	rm(metadata)


	### Keep only the good SRA and get them in the same order
	mm = match(colnames(coverageMatrix),sra_meta$run)
	sra_meta = sra_meta[mm,]
	pd = read_csv("https://raw.githubusercontent.com/nellore/runs/master/sra/v2/hg38/SraRunInfo.csv")
	sra_meta = left_join(as.data.frame(sra_meta),pd,by=c("run"="Run","sample"="Sample"))



	### define if it is a cell line or not in SRA
	b<-grep("cell line", sra_meta$characteristics)
	d<-grep("tissue", sra_meta$characteristics)
	## manually went through, if it is both "cell line" AND "tissue", it's a cell line. 
	d <- d[!(d %in% b)]

	#9644 samples
	# assign cell line vs. not in R
	celllines = rep(NA, nrow(sra_meta))
	celllines[b] <- "cell_line" #12,113
	celllines[d] <- "tissue"	#9,644
	sra_meta$SampleSource <- as.factor(celllines)

	sra_meta_training <<- sra_meta[keep,]
	sra_meta_test <<- sra_meta[!keep,]

	phenot = "SampleSource"

	new_meta = sra_meta[!is.na(sra_meta$SampleSource),]

    sra_meta_nopheno_NAs = sra_meta_training[is.na(sra_meta_training$SampleSource),]
 	sra_meta_training_noNAs = sra_meta_training[!is.na(sra_meta_training$SampleSource),]

	summary(as.factor(sra_meta$SampleSource))
	# cell_line    tissue      NA's
	#      9644     12113     27900
	summary(as.factor(sra_meta_training$SampleSource))


	## to ensure that all cell line and all tissue data are not coming from a few limited projects 
	## (which would likely just pick up batch)
	# > length(unique(sra_meta$ProjectID[b]))
	# [1] 543
	# > length(unique(sra_meta$ProjectID[d]))
	# [1] 661

  ## have to go through and select regions from each chunk that specify library prep
	regions_split <- split(reg, reg$chunkname)

	sra_meta$SampleSource <- as.factor(sra_meta$SampleSource)

if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_SampleSource.Rdata")){

	xx <- lapply(chunk_name, function(chunk_name) {
	     message(paste(Sys.time(), 'processing', chunk_name))
	      
	     ## Load coverage matrix for each chunk [coverageMatrix]
	     load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/coverageMatrix-cut0.5-', chunk_name, '.Rdata'))

	      ## Load regions included in the chunk [regions_subset]
	     load(paste0('/dcl01/leek/data/gtex_work/runs/sra/DER_analysis/coverageMatrix/ers_gtex/regions_', chunk_name, '-cut0.5.Rdata'))

	     ## split into training and test 
	     sra_training = coverageMatrix[,keep]
	     sra_test = coverageMatrix[,!keep]

	     #sra_meta_training <<- sra_meta[keep,]
	     #sra_meta_test <<- sra_meta[!keep,]

	     ## remove NA samples
	      sra_training_nophenotype = sra_training[,is.na(sra_meta_training$SampleSource)]
	      sra_training = sra_training[,!is.na(sra_meta_training$SampleSource)]
	      
	     ### Ftest

	     ## quick and dirty test to minimize number of regions input 
	     if(length(names(table(sra_meta_training_noNAs[,phenot])))==2){
	     	subs = rowttests(sra_training,factor(sra_meta_training_noNAs[,phenot]))
	     }else(
	     	subs = rowFtests(sra_training,factor(sra_meta_training_noNAs[,phenot]))
	     )

	     cutoff = quantile(subs$p.value,0.05)
	     tokeep<-subs$p.value<cutoff
	    sra_training = log2(sra_training[tokeep,]+1)
	    sra_test = log2(sra_test[tokeep,]+1)
		regions_subset = regions_subset[tokeep]

	
		# cellline = sra_meta_training$SampleSource
		# #remove NAs
		# sra_meta_training<-sra_meta_training[,!is.na(cellline)]


	      ## Select regions associated with LibraryPrep
   		 inputdata<-select_regions(expression=sra_training, regiondata=regions_subset ,phenodata=sra_meta_training_noNAs, phenotype=phenot, covariates=NULL,type="factor", numRegions=40)

   		new<-extract_data(newexpression=sra_test, newregiondata=regions_subset, predictordata=inputdata)

   		sra_training_nopheno <- extract_data(newexpression=sra_training_nophenotype, newregiondata=regions_subset, predictordata=inputdata)
    	inputdata$sra_test <- new
    	inputdata$sra_training_nopheno <- sra_training_nopheno
 
	      ## Finish
	      return(inputdata)
	  })
	names(xx) <- chunk_name

	  ## compile the subset of regions into a single object
	  merge_input<- merge_input(inputdata_list=xx)

	#remove "id"column
	merge_input$covmat = dplyr::select(merge_input$covmat, -(.id))

	  save(merge_input,file='/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_SampleSource.Rdata')
	}else{
	  load('/dcl01/leek/data/sellis/barcoding/data/SRA_inputdata_SampleSource.Rdata')
	}

# taking a look at output of select_regions)
dim(merge_input$covmat)
merge_input$regiondata

```


# Build predictor in SRA training data

```{r 'build-predictor', message = FALSE, warning = FALSE}
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/merge_input_SampleSource_nocovars.rda")) {

	#merge_input$covmat <- merge_input$covmat[,!is.na(sra_meta_training$SampleSource)]
	#sra_meta_training <- sra_meta_training[!is.na(sra_meta_training$SampleSource),]

	predictor<-build_predictor(inputdata=merge_input ,phenodata=sra_meta_training_noNAs, phenotype=phenot,
		covariates=NULL,type="factor", numRegions=100)
	save(predictor, file= "/dcl01/leek/data/sellis/barcoding/data/build_predictor_SampleSource_nocovars.rda")
}else{
	load('/dcl01/leek/data/sellis/barcoding/data/build_predictor_SampleSource_nocovars.rda')
}

#number of probes used for prediction
length(predictor$trainingProbes)

#this contains the coefficient estimates used for prediction. 
# the number of rows corresponds to the number of sites used for prediction
# while the columns corresponds to the number of categories of your phenotype.
dim(predictor$coefEsts)
```

# Plot expression for a few regions

```{r 'plot-regions', message = FALSE, ,fig.width=8, fig.height=4}
## take a look to see if it's actually picking out regions that distinguish...
## looking at expression at these regions
ov <-  findOverlaps(predictor$regiondata,merge_input$regiondata)
index_regions <- subjectHits(ov)
#reorder GRanges objects
test  <- merge_input$covmat[index_regions,]


for (i in 1:3){
expr = test[i,]
dat = as.data.frame(cbind(expr=as.numeric(expr),cell_line=as.character(sra_meta_training_noNAs$SampleSource)))
dat$cell_line <- as.factor(dat$cell_line)
# ggplot(dat, aes(x=expr, fill=cell_line)) + geom_density()

a <- as.numeric(expr[,sra_meta_training_noNAs$SampleSource=="cell_line"])
b <- as.numeric(expr[,sra_meta_training_noNAs$SampleSource!="cell_line"])


one = density(a)
two = density(b)
max(c(one$y,two$y)) -> ymax
min(c(one$y,two$y)) -> ymin

max(c(one$x,two$x)) -> xmax
min(c(one$x,two$x)) -> xmin


# pdf(paste0("plots/SampleSource_SamplesOutsideNull_",chrname,".pdf"),family="Roboto Condensed",width=8,height=8)
# par(mfrow=c(2,2))
	par(mfrow=c(1,2))
	boxplot(a,b, col=c(bright["orange"],bright["green"]))
	plot(density(a),lwd=2, col=bright["orange"], xlim=c(xmin,xmax), ylim=c(ymin,ymax),xlab="",main="")
	par(new=TRUE)
	plot(density(b),lwd=2, col=bright["green"], xlim=c(xmin,xmax), ylim=c(0,ymax),xlab="",main="")
	legend(xmax-13,ymax,legend=c(paste0("cell line"),paste0("tissue")),lwd=2,col=c(bright["orange"],bright["green"]), bty="n")
}

```

# Resubstitution Error (in SRA training)

```{r 'test-predictor', message = FALSE, warning = FALSE}
predictions_test <-test_predictor(inputdata=merge_input ,phenodata=sra_meta_training_noNAs, phenotype=phenot, 
    covariates=NULL,type="factor",predictordata=predictor )
# number of samples
length(predictions_test$predicted)

# get summary of how prediction is doing
predictions_test$summarized

summarized_training = predictions_test$summarized

predicted = predictions_test$predicted
actual = sra_meta_training_noNAs[,phenot]

perc_correct = sum(predicted==actual)/length(actual)

#get output for package
predictions_sra = as.data.frame(cbind(sra_meta_training_noNAs$run,"sra",actual=as.character(actual),predicted,perc_correct))
```


# Extract data for SRA test set

```{r 'extract-data', message = FALSE, warning = FALSE}
# looking at the input data for extract_data
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/sra_test_inputdata_SampleSource_nocovars.rda")) {

	purrr::map(xx, function(x){return(x$sra_test)}) %>% ldply(., data.frame) -> sra_test_covmat
	#remove "id"column
	sra_test_covmat= dplyr::select(sra_test_covmat, -(.id))
	colremove<-grep("regiondata", colnames(sra_test_covmat))
	sra_test_covmat= sra_test_covmat[, -colremove]

	  sra_test_inputdata=list()
	  ov <- findOverlaps(predictor$regiondata,merge_input$regiondata)
	  index_regions <- subjectHits(ov)
	  #reorder GRanges objects
	  sra_test_inputdata$covmat  <- sra_test_covmat[index_regions,]
	  sra_test_inputdata$regiondata <- merge_input$regiondata[index_regions]

	save(sra_test_inputdata, file= "/dcl01/leek/data/sellis/barcoding/data/sra_test_inputdata_SampleSource_nocovars.rda")
}else{
	load('/dcl01/leek/data/sellis/barcoding/data/sra_test_inputdata_SampleSource_nocovars.rda')
}
```

# Extract data for rest of SRA training set (no metadata samples)

```{r 'extract-data-nometadata', message = FALSE, warning = FALSE}

# looking at the input data for extract_data
if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/sra_nopheno_inputdata_SampleSource_nocovars.rda")) {

	purrr::map(xx, function(x){return(x$sra_training_nopheno)}) %>% ldply(., data.frame) -> sra_nopheno_covmat
	#remove "id"column
	sra_nopheno_covmat= dplyr::select(sra_nopheno_covmat, -(.id))
	colremove<-grep("regiondata", colnames(sra_nopheno_covmat))
	sra_nopheno_covmat= sra_nopheno_covmat[, -colremove]

	  sra_nopheno_inputdata=list()
	  ov <- findOverlaps(predictor$regiondata,merge_input$regiondata)
	  index_regions <- subjectHits(ov)
	  #reorder GRanges objects
	  sra_nopheno_inputdata$covmat  <- sra_nopheno_covmat[index_regions,]
	  sra_nopheno_inputdata$regiondata <- merge_input$regiondata[index_regions]

	save(sra_nopheno_inputdata, file= "/dcl01/leek/data/sellis/barcoding/data/sra_nopheno_inputdata_SampleSource_nocovars.rda")
}else{
	load('/dcl01/leek/data/sellis/barcoding/data/sra_nopheno_inputdata_SampleSource_nocovars.rda')
}
```

# Predict Sample Source in SRA test set

```{r 'predict-phenotype', message = FALSE, warning = FALSE}

predictions<-predict_pheno(inputdata_test= sra_test_inputdata, phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", predictordata = predictor)
# number of samples predicted
length(predictions)

#since we know the truth here, let's check and see how we're doing:
 
  actual_full = sra_meta_test[,phenot]
  samplesuse = !is.na(actual_full)
  actual = actual_full[samplesuse]
  meta_sub = sra_meta_test[samplesuse,]

  #define predicted
  predicted_full = predictions
  predicted = predicted_full[samplesuse]
  # number of samples w/ reported
  length(predicted)

  #summarize data
	number_match <- sum(predicted==actual)
	perc_correct = sum(predicted==actual)/length(actual)
	number_sites = nrow(predictor$coefEsts)

	summarized_test = cbind(number_sites,number_match, perc_correct)
	colnames(summarized_test) <- c("sites_tested", "number_correct", "percent_correct")
 
 #compare predictions to known sex
 summarized_test

#get output for package
predictions_sra_test = as.data.frame(cbind(sra_meta_test$run,"sra",actual=as.character(actual_full),predicted=predicted_full,perc_correct))
#update training set with test set perc_correct
predictions_sra$perc_correct <- perc_correct
```

# Predict Sample Source in unannotated SRA training set

```{r 'predict-phenotype-unannotated', message = FALSE, warning = FALSE}

predictions<-predict_pheno(inputdata_test= sra_nopheno_inputdata, phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", predictordata = predictor)
# number of samples predicted
length(predictions)

	#we don't know the truth here:
	actual = rep(NA,length(predictions))
  	#define predicted
  	predicted = predictions

  	perc_correct = NA

  
predictions_sra_train_nopheno = as.data.frame(cbind(sra_meta_nopheno_NAs$run,"sra",actual=actual,predicted=predicted,perc_correct))
```

# Predict Sequnencing Strategy in TCGA
```{r 'predict-phenotype-tcga', message = FALSE, warning = FALSE}

regions = predictor$regiondata

# get phenotype info in order
recount::all_metadata('TCGA') -> md 
bws = gsub('.bw','', md$bigwig_file)

if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/TCGA_SampSource_inputdata.rda")) {

  ## Extract same regions from TCGA data
  load('/dcl01/lieber/ajaffe/lab/gtex_ers/rse_TCGA.Rdata')
  findOverlaps(regions,rse) -> ov
  ## extract regions from predictor
  rse[subjectHits(ov)] -> rse_sub
  ## get coverage matrix ; order same as in regions
  ## note: these aren't scaled
  cov_tcga <- assays(rse_sub)$counts

  #ensure covmat is in same order as regions
  if( identical(tolower(bws),colnames(cov_tcga))==TRUE){
    covmat= cov_tcga
    regions = regions

    #remove coverage samples for which we don't have metadata
    covmat = covmat[,colnames(covmat) %in% tolower(bws)]

    #put data on a log2 scale
    dm = log2(covmat+1)
    md2 = md 
  }else{
    message("metadata and expression data not in same order")
  }

  tcga_meta2 = md2


  TCGA_inputdata=c()
  TCGA_inputdata$covmat <- dm
  TCGA_inputdata$regiondata <- predictor$regiondata

    ov <- findOverlaps(predictor$regiondata,TCGA_inputdata$regiondata)
    index_regions <- subjectHits(ov)
    #reorder GRanges objects
    TCGA_inputdata$regiondata <- TCGA_inputdata$regiondata[index_regions]
    TCGA_inputdata$covmat <- TCGA_inputdata$covmat[index_regions,]

    save(TCGA_inputdata, tcga_meta2, file="/dcl01/leek/data/sellis/barcoding/data/TCGA_SampSource_inputdata.rda")
}else{
  load("/dcl01/leek/data/sellis/barcoding/data/TCGA_SampSource_inputdata.rda")
}


  predictions_tcga<-predict_pheno(inputdata_test= TCGA_inputdata, phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", predictordata = predictor)

  # number of samples
  length(predictions_tcga)

  actual_all =  rep(c("tissue"),length(predictions_tcga))
  ## remove NAs from actual
  keep = !is.na(predictions_tcga)
  actual = actual_all[keep]
  #define predicted
  predicted = predictions_tcga[keep]



  #summarize data
  number_match <- sum(predicted==actual)
  perc_correct = sum(predicted==actual)/length(actual)
  number_sites = nrow(predictor$coefEsts)

  TCGA_summarized = as.data.frame(cbind(number_sites,number_match, perc_correct))
  names(TCGA_summarized) <- c("sites_tested", "number_correct", "percent_correct")
 
 #compare predictions to known sex
 TCGA_summarized

 #get output for package
predictions_tcga = as.data.frame(cbind(md$gdc_file_id,"tcga",actual=actual_all,predicted=predictions_tcga,perc_correct))

summarized_tcga = cbind(number_sites,number_match, perc_correct)
colnames(summarized_tcga) <- c("sites_tested", "number_correct", "percent_correct")

```

# Predict Sample Source in GTEx

```{r 'predict-phenotype-gtex', message = FALSE, warning = FALSE}
#get GTEx metadata
load("/dcl01/leek/data/sellis/barcoding/data/sample_individuals.Rdata")
load("/dcl01/leek/data/sellis/barcoding/data/rda/gtexmetadata.rda")
gtex_meta = gtexmetadata
gtex_meta = cbind(gtex_meta,usegtex)
rm(gtexmetadata,usegtex)
gtex_meta[is.na(gtex_meta[,"SMTS"]),"SMTS"] <- c("Esophagus","Skin","Stomach","Skin","Esophagus")
usegtex = gtex_meta$usegtex
pheno = gtex_meta
pheno = pheno[usegtex,]

if(!file.exists("/dcl01/leek/data/sellis/barcoding/data/regions_CellLine_GTEx.rda")) {

	system('sh /dcl01/leek/data/sellis/barcoding/scripts/run_bwtool_CellLine.sh gtex')

	tsv <- dir('/dcl01/leek/data/sellis/barcoding/GTEx/bwtool/coverage_gtex_CellLine', pattern = 'tsv', full.names = TRUE)
	names(tsv) <- gsub('.sum.tsv', '', dir('/dcl01/leek/data/sellis/barcoding/GTEx/bwtool/coverage_gtex_CellLine', pattern = 'tsv'))
	system.time( tsv_lines <- bplapply(tsv, countLines))
	all(tsv_lines == length(regions))

	multmerge = function(mypath){
		filenames=list.files(path=mypath, full.names=TRUE)
		datalist = lapply(filenames, function(x){
			read.table(file=x,header=F,sep='\t') 
		})
		Reduce(function(x,y) {cbind(x,y[,4])}, datalist)
	}

	mymergeddata = multmerge('/dcl01/leek/data/sellis/barcoding/GTEx/bwtool/coverage_gtex_CellLine')
	filenames=list.files(path='/dcl01/leek/data/sellis/barcoding/GTEx/bwtool/coverage_gtex_CellLine', full.names=FALSE)

	filenames = gsub('.sum.tsv', '', filenames)
	colnames(mymergeddata)[4:ncol(mymergeddata)] <- filenames

	cov_gtex = mymergeddata
	save(cov_gtex, file="/dcl01/leek/data/sellis/barcoding/data/regions_CellLine_GTEx.rda")
}else{	
	load("/dcl01/leek/data/sellis/barcoding/data/regions_CellLine_GTEx.rda")
}
covmat = cov_gtex[,4:ncol(cov_gtex)]
#only use keep GTEx samples
covmat = covmat[,usegtex]

# get phenotype info in order

#put data on a log2 scale
dm = log2(covmat+1)

gtex_test_inputdata = list()
gtex_test_inputdata$covmat <- dm
gtex_test_inputdata$regiondata <- regions

predictions_gtex<-predict_pheno(inputdata_test= gtex_test_inputdata, phenodata=sra_meta_training, phenotype=phenot, covariates=NULL,type="factor", predictordata = predictor)
# number of samples
length(predictions_gtex)

#since we know the truth here, let's check and see how we're doing: 
  actual = rep("tissue",length(predictions_gtex))

  #define predicted
  predicted = predictions_gtex

  #summarize data
	number_match <- sum(predicted==actual)
	perc_correct = sum(predicted==actual)/length(actual)
	number_sites = nrow(predictor$coefEsts)

	summarized_gtex = cbind(number_sites,number_match, perc_correct)
	colnames(summarized_gtex) <- c("sites_tested", "number_correct", "percent_correct")
 
 #compare predictions to known sex
 summarized_gtex

 #get output for package
predictions_gtex = as.data.frame(cbind(pheno$Run,"gtex",actual,predicted,perc_correct))

 ```

```{r 'plot-output', message = FALSE, warning = FALSE}

data = rbind(summarized_training,summarized_test,summarized_gtex,summarized_tcga) %>% data.frame()
t(data) %>% as.matrix() -> mat
colnames(mat) <- c("SRA: training","SRA: test","GTEx", "TCGA")
mat

colours2 = c(bright["teal"],bright["teal"],bright["purple"],bright["pink"])

# library(extrafont)
# pdf("/dcl01/leek/data/sellis/barcoding/plots/SampleSourcePrediction.pdf",family="Roboto Condensed",width=12, height=6)
par(cex=1.3)
barplot(as.numeric(mat["percent_correct",])*100, names.arg=c("SRA: training","SRA: test","GTEx","TCGA"),
        main="Sample Source", ylim=c(0,100), ylab="Accuracy", xlab="Data Set Used", col=colours2, cex.lab=1.3, cex.axis=1.2, cex.main=1.4)
axis(1, at=c(0,5), xpd=T, lwd.ticks = 0, labels=F)
# dev.off()

```

```{r 'pheno-output', message = FALSE, warning = FALSE}
predictions_SampleSource <- rbind(predictions_sra,predictions_sra_test,predictions_gtex,predictions_tcga,predictions_sra_train_nopheno)
colnames(predictions_SampleSource) <- c("sample_id","dataset","reported_samplesource","predicted_samplesource","accuracy_samplesource")
predictions_SampleSource$dataset <- factor(predictions_SampleSource$dataset)
predictions_SampleSource$reported_samplesource <- factor(predictions_SampleSource$reported_samplesource)
predictions_SampleSource$predicted_samplesource <- factor(predictions_SampleSource$predicted_samplesource)
predictions_SampleSource$accuracy_samplesource <- as.numeric(predictions_SampleSource$accuracy_samplesource)
sapply(predictions_SampleSource,class)

save(predictions_SampleSource, file="/dcl01/leek/data/sellis/barcoding/output/predictions_SampleSource.rda")
```

```{r 'region-information', message = FALSE, warning = FALSE}
## Get required information for the plots
if(!file.exists("/dcl01/leek/data/sellis/barcoding/output/SampleSource_regions.rda")) {	
	txdb <- GenomicFeatures::makeTxDbFromGFF('ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gff3.gz', format = 'gff3', organism = 'Homo sapiens')
	tx<-annotateTranscripts(txdb, annotationPackage = NULL, by = c("tx","gene"), codingOnly=FALSE, verbose = TRUE, requireAnnotation = FALSE)
	output<-matchGenes(predictor$regiondata, tx, type = c("any", "fiveprime"), promoterDist = 2500, skipExons = FALSE, verbose = TRUE)
	output
	save(output, file= "/dcl01/leek/data/sellis/barcoding/output/SampleSource_regions.rda")
}else{
	load("/dcl01/leek/data/sellis/barcoding/output/SampleSource_regions.rda")
	table(output$description)
}

```

# Vignette information

```{r reproducibility}
## Time spent creating this report:
diff(c(startTime, Sys.time()))

## Date this report was generated
message(Sys.time())

## Reproducibility info
options(width = 120)
devtools::session_info()
```

Code for creating the vignette

```{r createVignette, eval=FALSE}
## Create the vignette
library('rmarkdown')
system.time(render('/dcl01/leek/data/sellis/barcoding/phenotype_vignettes/phenopredict-SampleSource.Rmd', 'BiocStyle::html_document'))

## Extract the R code
library('knitr')
knit('/dcl01/leek/data/sellis/barcoding/phenotype_vignettes/phenopredict-SampleSource.Rmd', tangle = TRUE)
```


